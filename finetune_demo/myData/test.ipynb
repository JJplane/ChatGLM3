{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_chat_record(record):\n",
    "    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å‘è¨€è€…ã€æ—¶é—´å’Œå†…å®¹\n",
    "    # ç–å°”å·´å¥‡ (2021-05-27 22:37:05):æˆ‘æ¥å•¦ï¼\n",
    "    speaker = record.split(' ')[0]\n",
    "    time = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}', record)\n",
    "    if time:\n",
    "        time = time.group()\n",
    "    else:\n",
    "        time = None\n",
    "    content = record.split(':')[-1]\n",
    "    if speaker and time and content:\n",
    "        return speaker, time, content\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def parse_chat_records(filename):\n",
    "    parsed_records = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            parsed_record = parse_chat_record(line.strip())\n",
    "            if parsed_record:\n",
    "                parsed_records.append(parsed_record)\n",
    "    return parsed_records\n",
    "\n",
    "# è¯»å–èŠå¤©è®°å½•\n",
    "filename = 'chat.txt'\n",
    "records = parse_chat_records(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯´è¯äººæ”¹å˜åˆ™åˆ†å—\n",
    "chunks = []\n",
    "chunk = []\n",
    "for record in records:\n",
    "    if chunk and record[0] != chunk[-1][0]:\n",
    "        chunks.append(chunk)\n",
    "        chunk = []\n",
    "    # è®°å½•åªæœ‰[è¡¨æƒ…]ï¼Œ[è§†é¢‘/è¯­éŸ³é€šè¯]ï¼Œ[å›¾ç‰‡]ï¼Œåˆ™è·³è¿‡\n",
    "    if record[2] in ['[è¡¨æƒ…]', '[è§†é¢‘/è¯­éŸ³é€šè¯]', '[å›¾ç‰‡]']:\n",
    "        continue\n",
    "    chunk.append(record)\n",
    "chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# å¯¹äºæ¯ä¸ªå—ï¼Œå¦‚æœä¸€æ¡è®°å½•ç¦»ä¸Šä¸€æ¡è®°å½•çš„æ—¶é—´è¶…è¿‡äº”ä¸ªå°æ—¶ï¼Œåˆ™åˆ†å‰²è¿™ä¸ªå—ã€‚\n",
    "# ä¾‹å¦‚ï¼Œå¦‚æœä¸€æ¡è®°å½•çš„æ—¶é—´æ˜¯2021-05-27 22:37:05ï¼Œè€Œä¸Šä¸€æ¡è®°å½•çš„æ—¶é—´æ˜¯2021-05-27 17:37:05ï¼Œåˆ™åˆ†å‰²è¿™ä¸ªå—ã€‚\n",
    "# è¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº†é˜²æ­¢ä¸€æ¬¡èŠå¤©ä¸­é—´æœ‰å¾ˆé•¿æ—¶é—´çš„ç©ºæ¡£ã€‚\n",
    "# ä¾‹å¦‚ï¼Œå¦‚æœä¸€æ¬¡èŠå¤©ä¸­é—´æœ‰ä¸€æ®µæ—¶é—´æ²¡æœ‰èŠå¤©è®°å½•ï¼Œé‚£ä¹ˆè¿™æ®µæ—¶é—´çš„è®°å½•å°±ä¸åº”è¯¥è¢«ç”¨äºè®­ç»ƒã€‚\n",
    "new_chunks = []\n",
    "for chunk in chunks:\n",
    "    new_chunk = []\n",
    "    for i in range(len(chunk)):\n",
    "        if i == 0 or (datetime.strptime(chunk[i][1], '%Y-%m-%d %H:%M:%S') - datetime.strptime(chunk[i - 1][1], '%Y-%m-%d %H:%M:%S')).seconds <= 5 * 60 * 60:\n",
    "            new_chunk.append(chunk[i])\n",
    "        else:\n",
    "            new_chunks.append(new_chunk)\n",
    "            new_chunk = []\n",
    "    new_chunks.append(new_chunk)\n",
    "# åˆ é™¤ç©ºå—\n",
    "new_chunks = [chunk for chunk in new_chunks if chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "# æ‰¾åˆ°ç–å°”å·´å¥‡çš„chunkï¼Œä»¥åŠåé¢çš„åŠğŸ”çš„chunkï¼Œç»„æˆpair\n",
    "for i in range(len(new_chunks) - 1):\n",
    "    if new_chunks[i][0][0] == 'ç–å°”å·´å¥‡' and new_chunks[i + 1][0][0] == 'åŠğŸ”':\n",
    "        dataset.append({\"content\":'ã€‚'.join([record[2] for record in new_chunks[i]]),\"summary\":'ã€‚'.join([record[2] for record in new_chunks[i + 1]])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dataset.json', 'w') as file:\n",
    "    json.dump(dataset, file, ensure_ascii=False, indent=4)\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†1:99\n",
    "import random\n",
    "random.shuffle(dataset)\n",
    "testset = dataset[:int(len(dataset) * 0.01)]\n",
    "trainset = dataset[int(len(dataset) * 0.01):]\n",
    "# ä¿å­˜è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "with open('train.json', 'w') as file:\n",
    "    json.dump(trainset, file, ensure_ascii=False, indent=4)\n",
    "with open('dev.json', 'w') as file:\n",
    "    json.dump(testset, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
